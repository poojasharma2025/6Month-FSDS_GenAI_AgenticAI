{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bcb8621",
   "metadata": {},
   "source": [
    "### NLTK and SPACY difference ? Resume project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00246242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\welcome\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\welcome\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Using cached spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "Installing collected packages: spacy\n",
      "Successfully installed spacy-3.8.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install spacy  # library where we work nlp projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df03a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 4.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.9 MB/s  0:00:03\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm   # en-english text sm small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.K.StartUp for $1 Billion."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# Load the English language model \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Example text\n",
    "text = 'Apple is looking at buying U.K.StartUp for $1 Billion.'\n",
    "\n",
    "# process the text\n",
    "doc = nlp(text) \n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e469c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities, phrases and concepts\n",
      "Apple          ORG                0         5\n",
      "$1 Billion     MONEY             43        53\n"
     ]
    }
   ],
   "source": [
    "# Print named entities found in the text\n",
    "print('Named Entities, phrases and concepts')\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:15}{ent.label_:10}{ent.start_char:10}{ent.end_char:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b704a",
   "metadata": {},
   "source": [
    "## Text Summmarization --spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47db4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data science and AI & Gen AI  has great career ahead"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('data science and AI & Gen AI  has great career ahead')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc0017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aaec2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ea4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "science\n",
      "and\n",
      "AI\n",
      "&\n",
      "Gen\n",
      "AI\n",
      " \n",
      "has\n",
      "great\n",
      "career\n",
      "ahead\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc984fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n",
      "NOUN\n",
      "CCONJ\n",
      "PROPN\n",
      "CCONJ\n",
      "PROPN\n",
      "PROPN\n",
      "SPACE\n",
      "VERB\n",
      "ADJ\n",
      "NOUN\n",
      "ADV\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab05b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN\n",
      "science : NOUN\n",
      "and : CCONJ\n",
      "AI : PROPN\n",
      "& : CCONJ\n",
      "Gen : PROPN\n",
      "AI : PROPN\n",
      "  : SPACE\n",
      "has : VERB\n",
      "great : ADJ\n",
      "career : NOUN\n",
      "ahead : ADV\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,':',token.pos_)  # part of speech pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN --> data compound\n",
      "science : NOUN --> science nsubj\n",
      "and : CCONJ --> and cc\n",
      "AI : PROPN --> AI conj\n",
      "& : CCONJ --> & cc\n",
      "Gen : PROPN --> Gen compound\n",
      "AI : PROPN --> AI conj\n",
      "  : SPACE -->   dep\n",
      "has : VERB --> have ROOT\n",
      "great : ADJ --> great amod\n",
      "career : NOUN --> career dobj\n",
      "ahead : ADV --> ahead advmod\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,':',token.pos_,'-->',token.lemma_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b393098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data NOUN data NN compound xxxx True False\n",
      "science NOUN science NN nsubj xxxx True False\n",
      "and CCONJ and CC cc xxx True True\n",
      "AI PROPN AI NNP conj XX True False\n",
      "& CCONJ & CC cc & False False\n",
      "Gen PROPN Gen NNP compound Xxx True False\n",
      "AI PROPN AI NNP conj XX True False\n",
      "  SPACE   _SP dep   False False\n",
      "has VERB have VBZ ROOT xxx True True\n",
      "great ADJ great JJ amod xxxx True False\n",
      "career NOUN career NN dobj xxxx True False\n",
      "ahead ADV ahead RB advmod xxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.lemma_,token.tag_,token.dep_,token.shape_,token.is_alpha,token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd075ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=  \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4d9f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa9723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17442d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whose',\n",
       " 'much',\n",
       " 'whether',\n",
       " 'about',\n",
       " 'within',\n",
       " \"'d\",\n",
       " 'amount',\n",
       " 'six',\n",
       " 'almost',\n",
       " 'became',\n",
       " 'via',\n",
       " 'latter',\n",
       " 'since',\n",
       " 'had',\n",
       " 'made',\n",
       " 'namely',\n",
       " 'until',\n",
       " 'done',\n",
       " 'call',\n",
       " 'part',\n",
       " 'only',\n",
       " 'seem',\n",
       " 'nowhere',\n",
       " 'hereupon',\n",
       " 'thru',\n",
       " 'alone',\n",
       " 'those',\n",
       " 'either',\n",
       " 'seeming',\n",
       " 'other',\n",
       " 'next',\n",
       " 'full',\n",
       " 'thereby',\n",
       " 'whatever',\n",
       " 'front',\n",
       " 'him',\n",
       " 'some',\n",
       " 'toward',\n",
       " 'when',\n",
       " 'something',\n",
       " 'again',\n",
       " 'the',\n",
       " '’ve',\n",
       " 'me',\n",
       " 'herein',\n",
       " 'what',\n",
       " 'hence',\n",
       " 'another',\n",
       " 'hers',\n",
       " 'eight',\n",
       " 'whence',\n",
       " 'five',\n",
       " 'already',\n",
       " 'serious',\n",
       " 'of',\n",
       " 'everywhere',\n",
       " 'moreover',\n",
       " 'ten',\n",
       " 'ca',\n",
       " 'would',\n",
       " 'fifty',\n",
       " 'up',\n",
       " 'formerly',\n",
       " 'from',\n",
       " 'former',\n",
       " 'under',\n",
       " 'often',\n",
       " 'see',\n",
       " 'using',\n",
       " '‘re',\n",
       " 'yourselves',\n",
       " 'they',\n",
       " 'cannot',\n",
       " 'at',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'before',\n",
       " 'could',\n",
       " 'thus',\n",
       " 'us',\n",
       " 'not',\n",
       " 'beforehand',\n",
       " 'move',\n",
       " 'his',\n",
       " 'both',\n",
       " 'no',\n",
       " 'above',\n",
       " 'himself',\n",
       " 'nothing',\n",
       " 'yet',\n",
       " 'thereafter',\n",
       " 'anyone',\n",
       " 'together',\n",
       " 'besides',\n",
       " \"'re\",\n",
       " 'too',\n",
       " 'three',\n",
       " 'sixty',\n",
       " 'thereupon',\n",
       " 'enough',\n",
       " 'as',\n",
       " \"'ll\",\n",
       " 'she',\n",
       " 'onto',\n",
       " 'get',\n",
       " 'latterly',\n",
       " 'empty',\n",
       " 'why',\n",
       " 'mostly',\n",
       " 'an',\n",
       " 'except',\n",
       " 'hereafter',\n",
       " 'her',\n",
       " 'twenty',\n",
       " 'while',\n",
       " 'across',\n",
       " 'are',\n",
       " 'each',\n",
       " 'amongst',\n",
       " 'all',\n",
       " 'down',\n",
       " 'in',\n",
       " 'eleven',\n",
       " 'behind',\n",
       " 'sometimes',\n",
       " 'once',\n",
       " 'although',\n",
       " 'towards',\n",
       " 'rather',\n",
       " 'anywhere',\n",
       " 'wherein',\n",
       " 'various',\n",
       " 'whereafter',\n",
       " 'last',\n",
       " 'somehow',\n",
       " 'please',\n",
       " 'take',\n",
       " 'though',\n",
       " 'to',\n",
       " 'there',\n",
       " 'afterwards',\n",
       " 'less',\n",
       " 'give',\n",
       " 'so',\n",
       " 'should',\n",
       " 'twelve',\n",
       " 'anything',\n",
       " 'out',\n",
       " 'hereby',\n",
       " 'say',\n",
       " 'whenever',\n",
       " 'might',\n",
       " 'anyhow',\n",
       " 'beside',\n",
       " 'nor',\n",
       " \"'m\",\n",
       " 'over',\n",
       " 'beyond',\n",
       " 'regarding',\n",
       " 'whoever',\n",
       " 'thence',\n",
       " 'keep',\n",
       " 'which',\n",
       " 'he',\n",
       " 'than',\n",
       " 'several',\n",
       " 'these',\n",
       " 'none',\n",
       " '’ll',\n",
       " 'myself',\n",
       " 'into',\n",
       " 'nobody',\n",
       " 'it',\n",
       " 'then',\n",
       " 'their',\n",
       " 'were',\n",
       " 'is',\n",
       " 'without',\n",
       " 'back',\n",
       " 'name',\n",
       " 'against',\n",
       " 'own',\n",
       " '’s',\n",
       " 'further',\n",
       " 'has',\n",
       " 'same',\n",
       " 'everyone',\n",
       " 'a',\n",
       " 'may',\n",
       " 'been',\n",
       " 'meanwhile',\n",
       " 'third',\n",
       " 'well',\n",
       " 'be',\n",
       " 'sometime',\n",
       " 'therefore',\n",
       " 'our',\n",
       " 'itself',\n",
       " 'one',\n",
       " 'who',\n",
       " 'n’t',\n",
       " 'throughout',\n",
       " \"'ve\",\n",
       " \"n't\",\n",
       " 'doing',\n",
       " 'them',\n",
       " 'anyway',\n",
       " 'if',\n",
       " 'seemed',\n",
       " 'after',\n",
       " 'else',\n",
       " 'hundred',\n",
       " 'being',\n",
       " 'below',\n",
       " '‘s',\n",
       " 'ourselves',\n",
       " 'someone',\n",
       " 'four',\n",
       " 'still',\n",
       " 'on',\n",
       " 'through',\n",
       " 'and',\n",
       " 'side',\n",
       " 'themselves',\n",
       " 'show',\n",
       " 'was',\n",
       " 'among',\n",
       " 'how',\n",
       " 'your',\n",
       " 'neither',\n",
       " 'however',\n",
       " 'least',\n",
       " 'even',\n",
       " '‘m',\n",
       " 'therein',\n",
       " 'whereby',\n",
       " 'somewhere',\n",
       " 'yourself',\n",
       " '‘ll',\n",
       " 'perhaps',\n",
       " 're',\n",
       " 'did',\n",
       " 'most',\n",
       " 'herself',\n",
       " 'elsewhere',\n",
       " 'also',\n",
       " 'does',\n",
       " 'during',\n",
       " '’m',\n",
       " 'because',\n",
       " 'quite',\n",
       " 'whom',\n",
       " 'very',\n",
       " 'can',\n",
       " 'mine',\n",
       " 'per',\n",
       " 'fifteen',\n",
       " 'becomes',\n",
       " 'that',\n",
       " 'its',\n",
       " 'off',\n",
       " 'make',\n",
       " '‘ve',\n",
       " 'forty',\n",
       " 'seems',\n",
       " 'others',\n",
       " 'top',\n",
       " 'yours',\n",
       " '’d',\n",
       " 'few',\n",
       " 'around',\n",
       " 'here',\n",
       " 'now',\n",
       " 'any',\n",
       " 'used',\n",
       " 'two',\n",
       " 'always',\n",
       " 'upon',\n",
       " 'noone',\n",
       " 'am',\n",
       " 'whereas',\n",
       " 'i',\n",
       " 'n‘t',\n",
       " 'this',\n",
       " 'become',\n",
       " 'or',\n",
       " 'nine',\n",
       " 'first',\n",
       " 'whole',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " '‘d',\n",
       " 'we',\n",
       " 'between',\n",
       " \"'s\",\n",
       " 'by',\n",
       " 'such',\n",
       " 'have',\n",
       " 'unless',\n",
       " 'will',\n",
       " 'where',\n",
       " 'whither',\n",
       " 'really',\n",
       " 'otherwise',\n",
       " 'do',\n",
       " 'along',\n",
       " 'becoming',\n",
       " 'everything',\n",
       " 'put',\n",
       " 'my',\n",
       " '’re',\n",
       " 'bottom',\n",
       " 'due',\n",
       " 'you',\n",
       " 'but',\n",
       " 'with',\n",
       " 'indeed',\n",
       " 'whereupon',\n",
       " 'many',\n",
       " 'go',\n",
       " 'more',\n",
       " 'must',\n",
       " 'just',\n",
       " 'ours',\n",
       " 'every',\n",
       " 'wherever']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7626f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b118d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ca39dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', '\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', '\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[4', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured']\n"
     ]
    }
   ],
   "source": [
    "# find important sentence from the paragraph\n",
    "# 1.convert para-sentence \n",
    "# 2.sent-tokens | para-tokens\n",
    "# 3.frequency of token\n",
    "# 4.weighted frequency of then individual freq. / max freq.\n",
    "# 5.freq. score\n",
    "# 6. sent- if i merge all token score -- sentence score\n",
    "\n",
    "# lets get the token from text\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)\n",
    "# when we execute everything we created tokens from the text & not removed any of the stopword & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38c47fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to calcualte the freaquency of each and every word, how many time word is repetation in text \n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 1,\n",
       " 'types': 1,\n",
       " 'extractive': 1,\n",
       " 'summarization': 11,\n",
       " 'tasks': 1,\n",
       " 'depending': 2,\n",
       " 'program': 1,\n",
       " 'focuses': 2,\n",
       " 'generic': 3,\n",
       " 'obtaining': 1,\n",
       " 'summary': 4,\n",
       " 'abstract': 2,\n",
       " 'collection': 3,\n",
       " 'documents': 2,\n",
       " 'sets': 1,\n",
       " 'images': 3,\n",
       " 'videos': 3,\n",
       " 'news': 4,\n",
       " 'stories': 1,\n",
       " 'etc': 1,\n",
       " 'second': 1,\n",
       " 'query': 4,\n",
       " 'relevant': 2,\n",
       " 'called': 2,\n",
       " 'based': 1,\n",
       " 'summarizes': 1,\n",
       " 'objects': 1,\n",
       " 'specific': 1,\n",
       " 'Summarization': 1,\n",
       " 'systems': 1,\n",
       " 'able': 1,\n",
       " 'create': 1,\n",
       " 'text': 1,\n",
       " 'summaries': 2,\n",
       " 'machine': 1,\n",
       " 'generated': 1,\n",
       " 'user': 1,\n",
       " 'needs': 1,\n",
       " '\\n': 2,\n",
       " 'example': 3,\n",
       " 'problem': 2,\n",
       " 'document': 4,\n",
       " 'attempts': 1,\n",
       " 'automatically': 3,\n",
       " 'produce': 1,\n",
       " 'given': 2,\n",
       " 'interested': 1,\n",
       " 'generating': 1,\n",
       " 'single': 1,\n",
       " 'source': 2,\n",
       " 'use': 1,\n",
       " 'multiple': 1,\n",
       " 'cluster': 1,\n",
       " 'articles': 3,\n",
       " 'topic': 2,\n",
       " 'multi': 1,\n",
       " 'related': 2,\n",
       " 'application': 2,\n",
       " 'summarizing': 1,\n",
       " 'Imagine': 1,\n",
       " 'system': 3,\n",
       " 'pulls': 1,\n",
       " 'web': 1,\n",
       " 'concisely': 1,\n",
       " 'represents': 1,\n",
       " 'latest': 1,\n",
       " 'Image': 1,\n",
       " 'automatic': 1,\n",
       " 'consists': 1,\n",
       " 'selecting': 1,\n",
       " 'representative': 2,\n",
       " 'set': 2,\n",
       " 'larger': 1,\n",
       " 'images.[4': 1,\n",
       " 'context': 1,\n",
       " 'useful': 1,\n",
       " 'results': 1,\n",
       " 'image': 1,\n",
       " 'exploration': 1,\n",
       " 'Video': 1,\n",
       " 'domain': 1,\n",
       " 'creates': 1,\n",
       " 'trailer': 1,\n",
       " 'long': 1,\n",
       " 'video': 1,\n",
       " 'applications': 1,\n",
       " 'consumer': 1,\n",
       " 'personal': 1,\n",
       " 'want': 2,\n",
       " 'skip': 1,\n",
       " 'boring': 2,\n",
       " 'repetitive': 1,\n",
       " 'actions': 1,\n",
       " 'Similarly': 1,\n",
       " 'surveillance': 1,\n",
       " 'extract': 1,\n",
       " 'important': 1,\n",
       " 'suspicious': 1,\n",
       " 'activity': 1,\n",
       " 'ignoring': 1,\n",
       " 'redundant': 1,\n",
       " 'frames': 1,\n",
       " 'captured': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c3c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea102d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get normalized/weighted frequencies you should devide all frequencies with 11\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ce16ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 0.09090909090909091,\n",
       " 'types': 0.09090909090909091,\n",
       " 'extractive': 0.09090909090909091,\n",
       " 'summarization': 1.0,\n",
       " 'tasks': 0.09090909090909091,\n",
       " 'depending': 0.18181818181818182,\n",
       " 'program': 0.09090909090909091,\n",
       " 'focuses': 0.18181818181818182,\n",
       " 'generic': 0.2727272727272727,\n",
       " 'obtaining': 0.09090909090909091,\n",
       " 'summary': 0.36363636363636365,\n",
       " 'abstract': 0.18181818181818182,\n",
       " 'collection': 0.2727272727272727,\n",
       " 'documents': 0.18181818181818182,\n",
       " 'sets': 0.09090909090909091,\n",
       " 'images': 0.2727272727272727,\n",
       " 'videos': 0.2727272727272727,\n",
       " 'news': 0.36363636363636365,\n",
       " 'stories': 0.09090909090909091,\n",
       " 'etc': 0.09090909090909091,\n",
       " 'second': 0.09090909090909091,\n",
       " 'query': 0.36363636363636365,\n",
       " 'relevant': 0.18181818181818182,\n",
       " 'called': 0.18181818181818182,\n",
       " 'based': 0.09090909090909091,\n",
       " 'summarizes': 0.09090909090909091,\n",
       " 'objects': 0.09090909090909091,\n",
       " 'specific': 0.09090909090909091,\n",
       " 'Summarization': 0.09090909090909091,\n",
       " 'systems': 0.09090909090909091,\n",
       " 'able': 0.09090909090909091,\n",
       " 'create': 0.09090909090909091,\n",
       " 'text': 0.09090909090909091,\n",
       " 'summaries': 0.18181818181818182,\n",
       " 'machine': 0.09090909090909091,\n",
       " 'generated': 0.09090909090909091,\n",
       " 'user': 0.09090909090909091,\n",
       " 'needs': 0.09090909090909091,\n",
       " '\\n': 0.18181818181818182,\n",
       " 'example': 0.2727272727272727,\n",
       " 'problem': 0.18181818181818182,\n",
       " 'document': 0.36363636363636365,\n",
       " 'attempts': 0.09090909090909091,\n",
       " 'automatically': 0.2727272727272727,\n",
       " 'produce': 0.09090909090909091,\n",
       " 'given': 0.18181818181818182,\n",
       " 'interested': 0.09090909090909091,\n",
       " 'generating': 0.09090909090909091,\n",
       " 'single': 0.09090909090909091,\n",
       " 'source': 0.18181818181818182,\n",
       " 'use': 0.09090909090909091,\n",
       " 'multiple': 0.09090909090909091,\n",
       " 'cluster': 0.09090909090909091,\n",
       " 'articles': 0.2727272727272727,\n",
       " 'topic': 0.18181818181818182,\n",
       " 'multi': 0.09090909090909091,\n",
       " 'related': 0.18181818181818182,\n",
       " 'application': 0.18181818181818182,\n",
       " 'summarizing': 0.09090909090909091,\n",
       " 'Imagine': 0.09090909090909091,\n",
       " 'system': 0.2727272727272727,\n",
       " 'pulls': 0.09090909090909091,\n",
       " 'web': 0.09090909090909091,\n",
       " 'concisely': 0.09090909090909091,\n",
       " 'represents': 0.09090909090909091,\n",
       " 'latest': 0.09090909090909091,\n",
       " 'Image': 0.09090909090909091,\n",
       " 'automatic': 0.09090909090909091,\n",
       " 'consists': 0.09090909090909091,\n",
       " 'selecting': 0.09090909090909091,\n",
       " 'representative': 0.18181818181818182,\n",
       " 'set': 0.18181818181818182,\n",
       " 'larger': 0.09090909090909091,\n",
       " 'images.[4': 0.09090909090909091,\n",
       " 'context': 0.09090909090909091,\n",
       " 'useful': 0.09090909090909091,\n",
       " 'results': 0.09090909090909091,\n",
       " 'image': 0.09090909090909091,\n",
       " 'exploration': 0.09090909090909091,\n",
       " 'Video': 0.09090909090909091,\n",
       " 'domain': 0.09090909090909091,\n",
       " 'creates': 0.09090909090909091,\n",
       " 'trailer': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'video': 0.09090909090909091,\n",
       " 'applications': 0.09090909090909091,\n",
       " 'consumer': 0.09090909090909091,\n",
       " 'personal': 0.09090909090909091,\n",
       " 'want': 0.18181818181818182,\n",
       " 'skip': 0.09090909090909091,\n",
       " 'boring': 0.18181818181818182,\n",
       " 'repetitive': 0.09090909090909091,\n",
       " 'actions': 0.09090909090909091,\n",
       " 'Similarly': 0.09090909090909091,\n",
       " 'surveillance': 0.09090909090909091,\n",
       " 'extract': 0.09090909090909091,\n",
       " 'important': 0.09090909090909091,\n",
       " 'suspicious': 0.09090909090909091,\n",
       " 'activity': 0.09090909090909091,\n",
       " 'ignoring': 0.09090909090909091,\n",
       " 'redundant': 0.09090909090909091,\n",
       " 'frames': 0.09090909090909091,\n",
       " 'captured': 0.09090909090909091}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "037dd5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9a8f928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we are going to calculate the sentence score, to calculate the sentence score \n",
    "sentence_scores = {}\n",
    "\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "069e78d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9c640d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb8e9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets say our case study was 30% sentence with maximum scores\n",
    "# heapq is datastructure it will print acending and descending order\n",
    "from heapq import nlargest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa124fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.4)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc23ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have to select maximum 4 sentences out of all sentences \n",
    "summary = nlargest(select_length,sentence_scores, key = sentence_scores.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a31f6fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaa7cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i need to combine these top 3 sentencs then \n",
    "\n",
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "990e5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
       " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
       " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n',\n",
       " 'Image collection summarization is another application example of automatic summarization.',\n",
       " 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42017a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
